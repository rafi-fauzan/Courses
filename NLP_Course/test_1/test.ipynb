{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('data_prep': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6da017db4405de7e7334531da20ce055dcc4d682cc6baf29d41232eca3e20501"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext.data as ttd\n",
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import random\n",
    "gpu = ('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"label\" : [0,1,1],\n",
    "    \"data\" : [\n",
    "        \"I Like Eggs and Ham.\",\n",
    "        \"Eggs I Like!\",\n",
    "        \"Ham and Eggs or Just Ham?\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label                       data\n",
       "0      0       I Like Eggs and Ham.\n",
       "1      1               Eggs I Like!\n",
       "2      1  Ham and Eggs or Just Ham?"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>I Like Eggs and Ham.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Eggs I Like!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Ham and Eggs or Just Ham?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(\n",
    "    sequential=True\n",
    "    ,batch_first=True\n",
    "    ,lower=True\n",
    "    ,tokenize='spacy'\n",
    "    ,pad_first=True\n",
    ")\n",
    "\n",
    "LABEL = ttd.Field(\n",
    "    sequential=False\n",
    "    ,use_vocab=False\n",
    "    ,is_target=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ttd.TabularDataset(\n",
    "    path='test.csv'\n",
    "    ,format='csv'\n",
    "    ,skip_header=True\n",
    "    ,fields=[('label', LABEL), ('data', TEXT)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = dataset.examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['eggs', 'i', 'like', '!']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "ex.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "ex.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset.split(0.66, random_state = random.seed(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f84bcf25820>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'ham': 2,\n",
       "             'and': 3,\n",
       "             'eggs': 4,\n",
       "             '.': 5,\n",
       "             '?': 6,\n",
       "             'i': 7,\n",
       "             'just': 8,\n",
       "             'like': 9,\n",
       "             'or': 10})"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'ham', 'and', 'eggs', '.', '?', 'i', 'just', 'like', 'or']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = ttd.Iterator.splits(\n",
    "    (train_dataset, test_dataset), sort_key=lambda x: len(x.data),\n",
    "    batch_size=2, device=gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "inputs: tensor([[ 1,  7,  9,  4,  3,  2,  5],\n        [ 2,  3,  4, 10,  8,  2,  6]]) shape: torch.Size([2, 7])\ntargets: tensor([0, 1]) shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_iter:\n",
    "    print('inputs:', inputs, 'shape:', inputs.shape)\n",
    "    print('targets:', targets, 'shape:', targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "inputs: tensor([[4, 7, 9, 0]]) shape: torch.Size([1, 4])\ntargets: tensor([1]) shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in test_iter:\n",
    "    print('inputs:', inputs, 'shape:', inputs.shape)\n",
    "    print('targets:', targets, 'shape:', targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_train = next(iter(train_iter))\n",
    "doc_train, label_train = batch_train\n",
    "batch_test = next(iter(test_iter))\n",
    "doc_test, label_test = batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 2,  3,  4, 10,  8,  2,  6])\ntensor([1, 7, 9, 4, 3, 2, 5])\ntensor([4, 7, 9, 0])\n"
     ]
    }
   ],
   "source": [
    "doc_1 = doc_train[0] # first train doc\n",
    "doc_2 = doc_train[1] # second train doc\n",
    "doc_3 = doc_test[0] # first test doc\n",
    "print(doc_1)\n",
    "print(doc_2)\n",
    "print(doc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ham', 'and', 'eggs', 'or', 'just', 'ham', '?']\n['<pad>', 'i', 'like', 'eggs', 'and', 'ham', '.']\n['eggs', 'i', 'like', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for n in range (1,4):\n",
    "    docs_ = []\n",
    "    for i in range (len(globals()['doc_%s' % n])):\n",
    "        x = globals()['doc_%s' % n][i].item()\n",
    "        doc = str(TEXT.vocab.itos[x])\n",
    "        docs_.append(doc)\n",
    "    print(docs_)\n",
    "    docs.append(docs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ham and eggs or just ham ?\n<pad> i like eggs and ham .\neggs i like <unk>\n"
     ]
    }
   ],
   "source": [
    "sentence_1 = docs[0]\n",
    "sentence_1 = ' '.join(sentence_1)\n",
    "sentence_2 = docs[1]\n",
    "sentence_2 = ' '.join(sentence_2)\n",
    "sentence_3 = docs[2]\n",
    "sentence_3 = ' '.join(sentence_3)\n",
    "print(sentence_1)\n",
    "print(sentence_2)\n",
    "print(sentence_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/rafifauzan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "from nltk import FreqDist\n",
    "nltk.download('averaged_perceptron_tagger') # for pos_tag\n",
    "nltk.download('maxent_ne_chunker') # for ner\n",
    "nltk.download('words') # for ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['i like eggs and ham.', 'eggs i like!', 'ham and eggs or just ham?']\n\n[['i', 'like', 'eggs', 'and', 'ham', '.'], ['eggs', 'i', 'like', '!'], ['ham', 'and', 'eggs', 'or', 'just', 'ham', '?']]\n\n[['like', 'eggs', 'ham', '.'], ['eggs', 'like', '!'], ['ham', 'eggs', 'ham', '?']]\n\n[['like', 'egg', 'ham', '.'], ['egg', 'like', '!'], ['ham', 'egg', 'ham', '?']]\n\n[FreqDist({'like': 1, 'egg': 1, 'ham': 1, '.': 1}), FreqDist({'egg': 1, 'like': 1, '!': 1}), FreqDist({'ham': 2, 'egg': 1, '?': 1})]\n\n[[('like', 'IN'), ('egg', 'NN'), ('ham', 'NN'), ('.', '.')], [('egg', 'NN'), ('like', 'IN'), ('!', '.')], [('ham', 'NN'), ('egg', 'NN'), ('ham', 'NN'), ('?', '.')]]\n\n['Joko Widodo', 'Joko Widodo', 'Republic', 'Indonesia', 'Susilo Bambang Yudhoyono', 'Republic', 'Indonesia', 'Jokowi']\n['Joko_Widodo', 'Joko_Widodo', 'Republic', 'Indonesia', 'Susilo_Bambang_Yudhoyono', 'Republic', 'Indonesia', 'Jokowi']\n"
     ]
    }
   ],
   "source": [
    "lower = [i.lower() for i in data['data']]\n",
    "print(lower)\n",
    "print('')\n",
    "\n",
    "tokenize = [nltk.word_tokenize(i) for i in lower]\n",
    "print(tokenize)\n",
    "print('')\n",
    "\n",
    "without_stopwords = [[j for j in tokenize[i] if j not in stopword] for i in range(len(tokenize))]\n",
    "# for i in range(len(tokenize)):\n",
    "#     _without_stopwords = [j for j in tokenize[i] if j not in stopword]\n",
    "#     without_stopwords.append(_without_stopwords)\n",
    "print(without_stopwords)\n",
    "print('')\n",
    "\n",
    "lemmatize = [[lemmatizer.lemmatize(j) for j in without_stopwords[i]] for i in range(len(without_stopwords))]\n",
    "print(lemmatize)\n",
    "print('')\n",
    "\n",
    "# character_freq = [[FreqDist(j) for j in lemmatize[i]] for i in range(len(lemmatize))]\n",
    "# print(character_freq)\n",
    "word_freq = [FreqDist(i) for i in lemmatize]\n",
    "print(word_freq)\n",
    "print('')\n",
    "\n",
    "pos_tag = [nltk.pos_tag(i) for i in lemmatize]\n",
    "print(pos_tag)\n",
    "print('')\n",
    "# CC, A COORDINATING CONJUNCTION; RB, AN ADVERBS; IN, A PREPOSITION; NN, A NOUN; AND JJ, AN ADJECTIVE.\n",
    "\n",
    "test = ('who is Joko Widodo, Joko Widodo is the president of Republic Indonesia, what about Susilo Bambang Yudhoyono, he is the Republic Indonesia president before Jokowi')\n",
    "tok = nltk.word_tokenize(test)\n",
    "pos = nltk.pos_tag(tok) \n",
    "ner = nltk.ne_chunk(pos)\n",
    "NE = [\" \".join(w for w, t in ele) for ele in ner if isinstance(ele, nltk.Tree)]\n",
    "print (NE)\n",
    "NE2 = [\"_\".join(w for w, t in ele) for ele in ner if isinstance(ele, nltk.Tree)]\n",
    "print (NE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'who is Joko Widodo, Joko Widodo is the president of Republic Indonesia, what about Susilo_Bambang_Yudhoyono, he is the Republic Indonesia president before Jokowi'"
      ]
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "source": [
    "t = test.replace(NE[4], NE2[4])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['(NE[0], NE2[0])', '(NE[1], NE2[1])', '(NE[2], NE2[2])', '(NE[3], NE2[3])', '(NE[4], NE2[4])', '(NE[5], NE2[5])', '(NE[6], NE2[6])', '(NE[7], NE2[7])']\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i, j in enumerate(NE):\n",
    "    a = b.append(f\"(NE[{i}], NE2[{i}])\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['eval(b[0])', 'eval(b[1])', 'eval(b[2])', 'eval(b[3])', 'eval(b[4])', 'eval(b[5])', 'eval(b[6])', 'eval(b[7])']\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for i in range(len(NE)):\n",
    "    a = f\"eval(b[{i}])\"\n",
    "    c.append(a)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "who is Joko_Widodo, Joko_Widodo is the president of Republic Indonesia, what about Susilo_Bambang_Yudhoyono, he is the Republic Indonesia president before Jokowi\n"
     ]
    }
   ],
   "source": [
    "s = test\n",
    "for r in (eval(b[0]), eval(b[4])):\n",
    "    s = s.replace(*r)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (<ipython-input-216-dd9ee159a183>, line 2)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-216-dd9ee159a183>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    string_a = re.sub(NE[0]|NE[1]), NE2[0]|NE2[1], test)\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "string_a = re.sub(NE[0]|NE[1]), NE2[0]|NE2[1], test)\n",
    "print(string_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-25059c5a5e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstring_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(cat|dog)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mark owns a dog and Mary owns a cat.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_prep/lib/python3.9/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "string_a = re.sub(r'(cat|dog)', 'pet', 'PET', \"Mark owns a dog and Mary owns a cat.\")\n",
    "print(string_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "a = [] \n",
    "for i in range(len(NE)):\n",
    "    b = i\n",
    "    a.append(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-836f840eaf9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a[len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'who is Joko Widodo, Joko Widodo is the president of Republic Indonesia'"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Eggs I Like!'"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "corpus_test = data['data'][1]\n",
    "corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Eggs I Like!']"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "tokenize = nltk.sent_tokenize(corpus_test)\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Eggs', 'I', 'Like', '!']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "tokenize_word = nltk.word_tokenize(corpus_test)\n",
    "tokenize_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               Review  Label\n",
       "0          this is good stuff love it      1\n",
       "1  this is so bad why did i bought it      0\n",
       "2                  man this is awfull      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>this is good stuff love it</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>this is so bad why did i bought it</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>man this is awfull</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "abc ={\n",
    "    'Review' : [\n",
    "        'this is good stuff love it',\n",
    "        'this is so bad why did i bought it',\n",
    "        'man this is awfull'\n",
    "        ],\n",
    "    'Label' : [1,0,0]\n",
    "    }\n",
    "data = pd.DataFrame(abc)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 0 1 1 1 1 0 0 1 1 0]\n [0 1 1 1 0 1 1 0 0 1 0 1 1]\n [1 0 0 0 0 1 0 0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()\n",
    "BOW = bow.fit_transform(data['Review'])\n",
    "print(BOW.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.         0.         0.         0.48359121 0.28561676\n  0.36778358 0.48359121 0.         0.         0.48359121 0.28561676\n  0.        ]\n [0.         0.39916886 0.39916886 0.39916886 0.         0.23575556\n  0.30357821 0.         0.         0.39916886 0.         0.23575556\n  0.39916886]\n [0.6088451  0.         0.         0.         0.         0.35959372\n  0.         0.         0.6088451  0.         0.         0.35959372\n  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "TFIDF = tfidf.fit_transform(data['Review'])\n",
    "print(TFIDF.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.69314718, 1.69314718, 1.69314718, 1.69314718, 1.69314718,\n",
       "       1.        , 1.28768207, 1.69314718, 1.69314718, 1.69314718,\n",
       "       1.69314718, 1.        , 1.69314718])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20.219153878051237\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "a=tfidf.idf_\n",
    "\n",
    "l2 = norm(a,1)\n",
    "\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class animal:\n",
    "    def __init__(self, breed):\n",
    "        self.breed =  breed\n",
    "    \n",
    "    def sound(self):\n",
    "        return print('Bark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = animal('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bark\n"
     ]
    }
   ],
   "source": [
    "dog.sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog(animal):\n",
    "    def __init__(self, breed, name):\n",
    "        super(Dog, self).__init__(breed)\n",
    "        self.name = name\n",
    "    \n",
    "    def bark(self):\n",
    "        return print('gug')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_1 = Dog('bulldog', 'dogy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'bulldog'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "dog_1.breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cube:\n",
    "    def __init__(self, l, w, h, t):\n",
    "        self.length = l\n",
    "        self.wide = w\n",
    "        self.height = h\n",
    "        self.type = t\n",
    "    \n",
    "    @classmethod\n",
    "    def test(cls):\n",
    "        return print('this is a cube')\n",
    "    \n",
    "    def whatisthis(self):\n",
    "        return cube.test()\n",
    "    \n",
    "    def luas(self):\n",
    "        return self.length * self.wide * self.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = cube(2, 3, 4, 'Cube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this is a cube\n"
     ]
    }
   ],
   "source": [
    "abc.whatisthis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class abc(cube):\n",
    "    def __init__(self, l, w, h, t):\n",
    "        super(abc, self).__init__(l, w, h, t)\n",
    "    \n",
    "    def contoh_1(self):\n",
    "        return cube.test()\n",
    "\n",
    "    @staticmethod\n",
    "    def contoh_2():\n",
    "        return print('this is static')\n",
    "\n",
    "    def contoh(self):\n",
    "        return print('contoh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = abc(4,5,6,'contoh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this is a cube\n"
     ]
    }
   ],
   "source": [
    "con.contoh_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 4]\n",
    "b = [4, 6, 7]\n",
    "\n",
    "c = list(map(lambda x,y: x + y, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5, 9, 11]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['s', 'a', 't'], ['s', 'u', 'n'], ['f', 'r', 'i']]\n"
     ]
    }
   ],
   "source": [
    "d = [\"sat\", \"sun\", \"fri\"]\n",
    "\n",
    "e = map(list, d)\n",
    "print(list(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n2\n3\n4\n"
     ]
    }
   ],
   "source": [
    "a = [print(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "odd\n"
     ]
    }
   ],
   "source": [
    "a = 821\n",
    "print('even' if a%2 == 0 else 'odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}